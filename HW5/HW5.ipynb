{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6Y6_dFIlp38",
        "outputId": "f1a15ddb-4f9d-4bc9-a390-71350f100ff7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uB0XlGzZlMlo"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "IMPORT PART\n",
        "'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer as Imputer\n",
        "# from smdt import data_processing\n",
        "# from smdt import molecular_descriptors\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rdkit\n",
        "import urllib.request\n",
        "import json\n",
        "from rdkit import Chem\n",
        "from regression import fit_Ridge\n",
        "from molecular_descriptors import getAllDescriptors as all_desc\n",
        "from utils import *\n",
        "from data_processing import *\n",
        "#import descriptors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the function of your choice from regression.py and the necessary imports for it -> it will perform hyperparameters tuning on selected regression model\n",
        "# find and import the corresponding model from sklearn\n",
        "# find and import the function that computes all molecular descriptors \"from .molecular_descriptors.py import ...\"\n",
        "\n",
        "'''\n",
        "DESCRIPTORS PART\n",
        "'''\n",
        "\n",
        "def Ridge(X_train, X_test, y_train, y_test):\n",
        "\n",
        "    a = Imputer(missing_values=np.nan, strategy='median')\n",
        "    b = StandardScaler()\n",
        "    c = SelectKBest(score_func=mutual_info_regression)\n",
        "    clf = RidgeCV(cv=10)\n",
        "    model = Pipeline([('impute', a), ('scaling', b), ('anova', c), ('rf', clf)])\n",
        "\n",
        "    # Grid Search CV\n",
        "    parameters = {'anova__k': [5, 10, 20, 40]}\n",
        "\n",
        "    grid = GridSearchCV(model, parameters)\n",
        "    grid.fit(X_train, y_train)\n",
        "    y_pred = grid.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    metric = [grid.score(X_test, y_test),\n",
        "               metrics.explained_variance_score(y_test, y_pred),\n",
        "               metrics.mean_absolute_error(y_test, y_pred),\n",
        "               metrics.mean_squared_error(y_test, y_pred),\n",
        "               metrics.median_absolute_error(y_test, y_pred),\n",
        "               metrics.r2_score(y_test, y_pred)]\n",
        "\n",
        "    return grid, y_pred, metric\n",
        "\n",
        "def desc_calc(data, mode='', log=None) -> pd.DataFrame:\n",
        "    descriptors = all_desc(data, mode, log)\n",
        "    return descriptors\n",
        "\n",
        "def sar_model_evaluation(descriptors: pd.DataFrame):\n",
        "\n",
        "    '''\n",
        "    Function for model evaluation with functionCopyFromRegression().\n",
        "    Saves best model.\n",
        "    '''\n",
        "\n",
        "    y = descriptors['Target']\n",
        "    X = descriptors.drop(columns=['Target'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "    model1, y_pred1, metrics1 = Ridge(X_train, X_test, y_train, y_test)\n",
        "    return model1, y_pred1, metrics1\n",
        "\n",
        "def sar_model_train(descriptors_train: pd.DataFrame, indices):\n",
        "\n",
        "    '''\n",
        "    Function for training the model with best paramaters.\n",
        "    Don't forget to add here the input arguments required by the selected model.\n",
        "    '''\n",
        "\n",
        "    y_train = descriptors_train['Target']\n",
        "    X_train = descriptors_train.drop(columns=['Target'])\n",
        "    X_train = X_train[X_train.columns[indices]]\n",
        "\n",
        "    a = Imputer(missing_values=np.nan, strategy='median')\n",
        "    b = StandardScaler()\n",
        "    clf = LassoCV()\n",
        "    model = Pipeline([('impute', a), ('scaling', b), ('rf', clf)]) # without ANOVA now\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def sar_model_predict(model, descriptors_pred, indices):\n",
        "\n",
        "    '''\n",
        "    Function for casting predictions on unseen data\n",
        "    '''\n",
        "\n",
        "    X_pred = descriptors_pred\n",
        "    X_pred = X_pred[X_pred.columns[indices]]\n",
        "    return model.predict(X_pred)\n",
        "\n",
        "\n",
        "'''\n",
        "PUBCHEM PART\n",
        "'''\n",
        "\n",
        "def pubchem_parsing(url):\n",
        "\n",
        "    '''\n",
        "    Function for Pubchem request\n",
        "    '''\n",
        "\n",
        "    req = urllib.request.Request(url)\n",
        "    res = urllib.request.urlopen(req).read()\n",
        "    fin = json.loads(res.decode())\n",
        "    return fin\n",
        "\n",
        "\n",
        "def get_similar_cids(compound_smiles, threshold=95, maxentries=10):\n",
        "\n",
        "    '''\n",
        "    Function for finding similar CIDS in PubChem with fastsimilarity_2d\n",
        "    '''\n",
        "\n",
        "    pubchem_pug_rest_api_link = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/\"\n",
        "    pubchem_pug_rest_api_link+= \"fastsimilarity_2d/smiles/%(smiles)s/cids/JSON?Threshold=%(threshold)s&MaxRecords=%(maxentries)s\" % {\n",
        "        \"smiles\": compound_smiles, \"threshold\": threshold, \"maxentries\": maxentries}\n",
        "    similar_cids = pubchem_parsing(pubchem_pug_rest_api_link)['IdentifierList']['CID']\n",
        "    return similar_cids\n",
        "\n",
        "\n",
        "def get_xlogp(compound_cid):\n",
        "\n",
        "    '''\n",
        "    Function for parsing XLogP from the response\n",
        "    '''\n",
        "\n",
        "    pubchem_pug_rest_api_link = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/\"\n",
        "    pubchem_pug_rest_api_link += \"compound/cid/%s/property/XLogP/JSON\" % compound_cid\n",
        "\n",
        "    try:\n",
        "        xlogp = pubchem_parsing(pubchem_pug_rest_api_link)['PropertyTable']['Properties'][0]['XLogP']\n",
        "        return xlogp\n",
        "    except KeyError:\n",
        "        return None\n",
        "\n",
        "\n",
        "'''\n",
        "MAIN PART\n",
        "'''\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    pd.set_option.use_inf_as_na = True\n",
        "\n",
        "    # loading data\n",
        "    # train_data = pd.read_csv('logp_100.csv')\n",
        "    train_data = pd.read_csv('logp_full.csv')\n",
        "    pred_data = pd.read_csv('logp_inputs.csv')\n",
        "    cpds = [row for row in pred_data.loc[:, 'SMILES']]\n",
        "\n",
        "    # calculating descriptors\n",
        "    print(\"Calculating descriptors for training data...\")\n",
        "    train_descriptors = desc_calc(train_data, mode='train')\n",
        "    print(\"Calculating descriptors for prediction data...\")\n",
        "    pred_descriptors = desc_calc(pred_data)\n",
        "    # print(train_descriptors.head(), pred_descriptors.head())\n",
        "\n",
        "    # finding best estimator\n",
        "    print(\"Evaluating regression model parameters...\")\n",
        "    model = sar_model_evaluation(train_descriptors)\n",
        "    print('Best parameters are:', model[0].best_params_) # {'anova__k': 40}\n",
        "    cols = model[0].best_estimator_.named_steps['anova'].get_support(indices=True) # this are indices from ANOVA\n",
        "\n",
        "    # add here other parameters from GridSearchCV best estimator (e.g. alpha for Ridge Regression)\n",
        "\n",
        "    # train the best estimator and predict values\n",
        "    print(\"Training the model with the best parameters...\")\n",
        "    final_model = sar_model_train(train_descriptors, cols)\n",
        "\n",
        "    for cpd in cpds:\n",
        "        cpd_descriptors = pred_descriptors[pred_descriptors['SMILES']==cpd]\n",
        "        pred = sar_model_predict(final_model, cpd_descriptors, cols)\n",
        "        print(f\"Predicted LogP value for compound {cpd}:\", pred)\n",
        "\n",
        "        result = []\n",
        "\n",
        "        print(\"Searching for similar compunds...\")\n",
        "        similarity = get_similar_cids(cpd) # related pubchem function\n",
        "\n",
        "        print(\"Filtering logP...\")\n",
        "        for cid in similarity:\n",
        "            xlogp = get_xlogp(cid) # related pubchem function\n",
        "            if xlogp:\n",
        "                if xlogp <= pred*1.1 and xlogp >=pred*0.9:\n",
        "                    result.append((cid, xlogp))\n",
        "\n",
        "        print(f\"Request for compound {cpd} completed. I found the following CIDs in PubChem with XLogP in the range of {pred}+- 10%: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmO5Ae_ylNia",
        "outputId": "098d36e1-11ba-492e-f98c-0783972eab5d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating descriptors for training data...\n",
            "Calculating Molecular Descriptors Completed.\n",
            "Calculating descriptors for prediction data...\n",
            "Calculating Molecular Descriptors Completed.\n",
            "Evaluating regression model parameters...\n",
            "Best parameters are: {'anova__k': 40}\n",
            "Training the model with the best parameters...\n",
            "Predicted LogP value for compound CC1=CC2=C(C=C1C)NC(=O)CC2C3=CC=CC=C3OC: [4.0178873]\n",
            "Searching for similar compunds...\n",
            "Filtering logP...\n",
            "Request for compound CC1=CC2=C(C=C1C)NC(=O)CC2C3=CC=CC=C3OC completed. I found the following CIDs in PubChem with XLogP in the range of [4.0178873]+- 10%: [(2906028, 4), (17285549, 4.1)]\n",
            "Predicted LogP value for compound COC1=CC=C2C(=C1)OC(CC2=O)(C(F)(F)F)O: [2.84387697]\n",
            "Searching for similar compunds...\n",
            "Filtering logP...\n",
            "Request for compound COC1=CC=C2C(=C1)OC(CC2=O)(C(F)(F)F)O completed. I found the following CIDs in PubChem with XLogP in the range of [2.84387697]+- 10%: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_descriptors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s636z674ulkJ",
        "outputId": "90028060-cc3a-4870-b9f9-7edc658f0380"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       W        AW         J         Xu      GMTI   Pol    DZ       Ipc  \\\n",
            "0  844.0  4.019048  2.167149  20.028792  3.562412  36.0  44.5  4.843605   \n",
            "1  553.0  3.614379  2.466824  17.337284  3.330617  32.0  44.5  3.901845   \n",
            "\n",
            "    BertzCT      Thara  ...  ATSe8  ATSp1  ATSp2  ATSp3  ATSp4  ATSp5  ATSp6  \\\n",
            "0  2.849026  74.175794  ...   2.12  3.073  3.418  3.501  3.388  3.334  3.112   \n",
            "1  2.696838  59.053571  ...   1.68  2.687  2.996  3.014  2.754  2.404  2.039   \n",
            "\n",
            "   ATSp7  ATSp8  Target  \n",
            "0  2.676  2.009    4.17  \n",
            "1  1.667  0.670    2.79  \n",
            "\n",
            "[2 rows x 759 columns]\n"
          ]
        }
      ]
    }
  ]
}